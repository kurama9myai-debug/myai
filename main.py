# -*- coding: utf-8 -*-
import sys
sys.stdout.reconfigure(encoding='utf-8')

import streamlit as st
import os
from dotenv import load_dotenv
from openai import OpenAI

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙˆÚ©Ù† Ø§Ø² .env
load_dotenv()
HF_TOKEN = os.getenv("HF_TOKEN")

if not HF_TOKEN:
    st.error("âŒ ØªÙˆÚ©Ù† Hugging Face Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯. Ù„Ø·ÙØ§Ù‹ Ø¯Ø± ÙØ§ÛŒÙ„ .env Ù…Ù‚Ø¯Ø§Ø± HF_TOKEN Ø±Ø§ ØªÙ†Ø¸ÛŒÙ… Ú©Ù†.")
    st.stop()

# Ø³Ø§Ø®Øª Ú©Ù„Ø§ÛŒÙ†Øª Hugging Face
client = OpenAI(
    base_url="https://router.huggingface.co/v1",
    api_key=HF_TOKEN,
)

st.title("ğŸ¤– Ú†Øªâ€ŒØ¨Ø§Øª ÙØ§Ø±Ø³ÛŒ Ø¨Ø§ Llama 3 (Hugging Face)")

# Ø°Ø®ÛŒØ±Ù‡ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
if "messages" not in st.session_state:
    st.session_state.messages = []

# ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø±
user_input = st.text_input("Ø´Ù…Ø§:", "")

if st.button("Ø§Ø±Ø³Ø§Ù„") and user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})

    try:
        response = client.chat.completions.create(
            model="meta-llama/Meta-Llama-3-8B-Instruct",
            messages=st.session_state.messages
        )
        ai_reply = response.choices[0].message.content
        st.session_state.messages.append({"role": "assistant", "content": ai_reply})

    except Exception as e:
        st.error(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØªØµØ§Ù„: {e}")

# Ù†Ù…Ø§ÛŒØ´ Ú¯ÙØªÚ¯Ùˆ
for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.markdown(f"ğŸ‘¤ **Ø´Ù…Ø§:** {msg['content']}")
    else:
        st.markdown(f"ğŸ¤– **Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ:** {msg['content']}")
